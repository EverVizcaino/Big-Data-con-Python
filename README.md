# Big-Data-con-Python
Computuacion paralela con Python Spark corriendo en una mquina virtual AWS

Es un curso totalmente práctico y dinámico  desde cero con Spark.

Introducción al big data, a la computación paralela y a Apache Spark.

Llevaremos paso a paso para crear una cuenta de AWS, crear una máquina virtual utilizando el sistema de computación EC2 y configurar todo lo necesario para poder utilizar Spark y Jupyter Notebooks en AWS.

En las primeras partes del curso trabajamos con Spark y su formato RDD (Resilient Distributed Datasets o Datos Distribuidos Resilientes). Luego trabajaremos con Spark SQL y sus DataFrames y acabaremos aprendiendo a implementar un algoritmos de regresión lineal en Spark ML.

# Objetivos de aprendizaje
● Sobre el Big Data y la computación paralela
● A trabajar con Spark RDDs en pyspark
● A trabajar con Spark SQL y sus DataFrames en pyspark
● A trabajar con Spark MLlib en pyspark

# ¿Hay requisitos para realizar el curso?
Tener conocimientos básicos de programación en Python
# ¿Para quién es este curso?
Personas que se esten adentrando en el mundo del Big Data y quieran saber cómo trabajar con Spark y con Python
